{"/bensiegils/about/":{"data":{"1997-2002-mcse#1997-2002 MCSE":"Microsoft solutions Citrix Terminal Server Lotus Notes Domino Working at Alit/Sensa and supporting ISAL - Mjólkursamsalan - Íslandsflug and other small companies","2003-2010-vsp#2003-2010 VSP":"Datacenter Microsoft solutions VMware Hyper-V solutions Terminal Services / RDS Working at VSP supporting multiple companies with IT infrastructure","2010-2015-independent-consultant#2010-2015 Independent Consultant":"VMware infrastructure design and implementation Microsoft infrastructure solutions Datacenter migrations Various consulting projects for medium to large enterprises","2015-present-cloud-focus#2015-Present Cloud Focus":"Azure cloud architecture and implementation PowerShell automation and scripting Infrastructure as Code (Terraform, ARM templates) Security and compliance in cloud environments Continuous learning and certification in cloud technologies","about-me#About Me":"About Me","certifications#Certifications":"","certifications--skills#Certifications \u0026amp; Skills":"","contact--social#Contact \u0026amp; Social":"Feel free to connect with me on various platforms:\nGitHub: lubenz007 LinkedIn: Benedikt Gabriel Egilsson Twitter: @lubenz007 This blog represents my personal views and experiences. All content is shared for educational purposes and to contribute to the tech community.","current-certifications#Current Certifications":"Microsoft Azure Administrator Associate (AZ-104) Microsoft Azure Solutions Architect Expert (AZ-305)","it-professional-with-25-years-experience#IT Professional with 25+ Years Experience":"My background is in virtualization and IT administration, with a strong focus on system administration. Over the years, I have developed a deep understanding of various technologies, including:\nWindows - System administration and management Hyper-V \u0026 VMware - Virtualization technologies Linux - Server administration Datacenter - Infrastructure management Azure Cloud - Cloud computing and services I have a strong focus on automation and scripting, and I am always looking for ways to improve my skills and knowledge.\nThis blog is where I store my knowledge to look back on and share with others.\nNote: Check out my Microsoft Learn transcript here","technical-skills#Technical Skills":"Cloud Platforms: Microsoft Azure, AWS basics Virtualization: VMware vSphere, Hyper-V, Azure VMs Automation: PowerShell, Azure CLI, Terraform Operating Systems: Windows Server, Linux basics Networking: Azure networking, VPN, load balancing Security: Azure Security Center, compliance frameworks Monitoring: Azure Monitor, Log Analytics, alerting"},"title":"About Me"},"/bensiegils/archives/":{"data":{"post-archives#Post Archives":"Post ArchivesBrowse all blog posts organized by date."},"title":"Archives"},"/bensiegils/posts/":{"data":{"":"Here you’ll find all my blog posts about Azure, PowerShell, automation, security, and other technical topics.","latest-posts#Latest Posts":""},"title":"Blog Posts"},"/bensiegils/posts/2023-01-04-license-report/":{"data":{"":"Create a detailed report of licenses assigned to Azure AD user accounts using the Microsoft Graph API. This is a rewrite that uses direct API calls instead of the MgGraph PowerShell module.","license-reporting-with-microsoft-graph-api#License Reporting with Microsoft Graph API":"This is a rewrite from practical365.com - my mission was to rewrite the script to use the Microsoft Graph API instead of the MgGraph PowerShell module.\nInfo: This post shows how to get license reports from Microsoft Graph directly\n$ClientID = '' $ClientSecret = '' $tenant_Id = '' # Connect to Graph # $Body = @{ Grant_Type = \"client_credentials\" resource = \"https://graph.microsoft.com\" client_id = $clientId client_secret = $clientSecret } $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body # Variable Collections # $CSVOutputFile = \"c:\\temp\\Microsoft365LicensesReport.CSV\" $today = Get-Date $Headers = @{ 'Content-Type' = \"application/json\" 'Authorization' = \"Bearer $($ConnectGraph.access_token)\" } $token = $ConnectGraph.access_token # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 function Get-GraphData { param ( [parameter(Mandatory)] [string]$AccessToken, [parameter(Mandatory)] [string]$Uri ) $Headers = @{ 'Authorization' = \"Bearer $AccessToken\" } do { $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop $QueryResults += $Results.value $Uri = $Results.'@odata.nextLink' } while ($Uri) return $QueryResults } #This request get SecureScore [array]$Skus = Get-GraphData -AccessToken $Token -Uri \"https://graph.microsoft.com/beta/subscribedSkus\" #[Array]$Skus = Get-MgSubscribedSku # Generate CSV of all product SKUs used in tenant [array]$Sku = $Skus | Select-Object SkuId, SkuPartNumber # Generate list of all service plans used in SKUs in tenant $SPData = [System.Collections.Generic.List[Object]]::new() ForEach ($Sk in $Skus) { ForEach ($SP in $Sk.ServicePlans) { $SPLine = [PSCustomObject][Ordered]@{ ServicePlanId = $SP.ServicePlanId ServicePlanName = $SP.ServicePlanName ServicePlanDisplayName = $SP.ServicePlanName } $SPData.Add($SPLine) } } $SkuHashTable = @{} ForEach ($Line in $Sku) { $SkuHashTable.Add([string]$Line.SkuId, [string]$Line.skuPartNumber) } $ServicePlanHashTable = @{} ForEach ($Line2 in $SPData) { $ServicePlanHashTable.Add([string]$Line2.ServicePlanId, [string]$Line2.ServicePlanDisplayName) } [Array]$Users = Get-GraphData -AccessToken $Token -Uri \"https://graph.microsoft.com/beta/users\" $Report = [System.Collections.Generic.List[Object]]::new() ForEach ($User in $users) { If ([string]::IsNullOrWhiteSpace($User.AssignedLicenses) -eq $true) { # Only process account if it has some licenses Write-Host \"Processing\" $User.DisplayName [array]$LicenseInfo = $Null; [array]$DisabledPlans = $Null ForEach ($License in $User.AssignedLicenses) { If ($SkuHashTable.ContainsKey($License.SkuId) -eq $True) { # We found a match in the SKU hash table $LicenseInfo += $SkuHashTable.Item($License.SkuId) } Else { # Nothing doing, so output the SkuID $LicenseInfo += $License } # Report any disabled service plans in licenses If ([string]::IsNullOrWhiteSpace($License.DisabledPlans) -eq $False ) { # Check if disabled service plans in a license ForEach ($DisabledPlan in $License.DisabledPlans) { # Try and find what service plan is disabled If ($ServicePlanHashTable.ContainsKey($DisabledPlan) -eq $True) { # We found a match in the Service Plans hash table $DisabledPlans += $ServicePlanHashTable.Item($DisabledPlan) } Else { # Nothing doing, so output the Service Plan ID $DisabledPlans += $DisabledPlan } } # End ForEach disabled plans } # End if check for disabled plans } # End Foreach Licenses # Report information [string]$DisabledPlans = $DisabledPlans -join \", \" [string]$LicenseInfo = $LicenseInfo -join (\", \") $ReportLine = [PSCustomObject][Ordered]@{ User = $User.DisplayName UPN = $User.UserPrincipalName Country = $User.Country Department = $User.Department Title = $User.JobTitle Licenses = $LicenseInfo \"Disabled Plans\" = $DisabledPlans } Write-Host $ReportLine $Report.Add($ReportLine) } #end If account is licensed Else { $UnlicensedAccounts++ } } # End ForEach Users $Report | Export-CSV -NoTypeInformation $CSVOutputFile"},"title":"Getting licenses assigned to user accounts"},"/bensiegils/posts/2023-03-23-sgraph-api/":{"data":{"":"Microsoft Graph API is a powerful tool for authentication and authorization that allows developers to access Microsoft services and data securely. Learn how to integrate with Outlook, OneDrive, Office 365, Azure Active Directory, and more.","authentication#Authentication":"","authentication-and-authorization#Authentication and Authorization":"MSGraph API provides a secure way to authenticate users, authorize applications, and manage user data. With MSGraph API, developers can easily integrate their applications with Microsoft services like Outlook, OneDrive, Office 365, Azure Active Directory, and more.","we-will-use-the-azure-cli-to-create-a-service-principal-and-get-the-app-id-and-secret-we-will-also-use-the-azure-cli-to-view-all-the-api-permissions-available-in-microsoft-graph#We will use the Azure CLI to create a service principal and get the app id and secret. We will also use the Azure CLI to view all the API permissions available in Microsoft Graph.":"Info: Get the Azure CLI from here\n# login to Azure az login #View All API Permissions Microsoft Graph to see what is available $Permissions = az ad sp list --filter \"appId eq '00000003-0000-0000-c000-000000000000'\" | ConvertFrom-Json #to see all permissions $Permissions.appRoles | Select-Object -Property value,allowedMemberTypes,description # Get select permission from list above and id to use in next command $Permissions.appRoles | Select-Object -Property value,allowedMemberTypes,id,description | Where-Object {$_.value -eq \"User.Read.All\"} # Create service principal az ad app create --display-name \"Alit-GraphAPI\" # Graph API App ID: from output \"appId\": \"d52bda31-bd71-4a17-b563-7921a17d79e7\" # Reset app secret to get new secret az ad app credential reset --id \"d52bda31-bd71-4a17-b563-7921a17d79e7\" # Graph API App Secret: from output #{ # \"appId\": \"d52bda31-bd71-4a17-b563-7921a17d79e7\", # \"password\": \"3b3b3b3b-3b3b-3b3b-3b3b-3b3b3b3b3b3b\", # \"tenant\": \"5eeb8561-5493-4b39-906f-038356850aaa\" #} # set secret to 3 years #az ad app credential reset --id 13d15b6f-94ad-4df4-a88d-72f355e5f92d --years 3 # Add Microsoft Graph application permission user.read.all # Guide https://learn.microsoft.com/en-us/cli/azure/ad/app/permission?view=azure-cli-latest az ad app permission add --id d52bda31-bd71-4a17-b563-7921a17d79e7 --api 00000003-0000-0000-c000-000000000000 --api-permissions df021288-bdef-4463-88db-98f22de89214=Role # Grant admin consent #this needs to be done by a Cloud Application Administrator az ad app permission admin-consent --id d52bda31-bd71-4a17-b563-7921a17d79e7 # Get app id az ad app list --query \"[?displayName=='Alit-GraphAPI'].{id:appId,secret:passwordCredentials[0].value}\" #{ # \"id\": \"d52bda31-bd71-4a17-b563-7921a17d79e7\", # \"secret\": null # } #get app api permissions az ad app permission list --id d52bda31-bd71-4a17-b563-7921a17d79e7 --output json #{ # \"resourceAccess\": [ # { # \"id\": \"df021288-bdef-4463-88db-98f22de89214\", # \"type\": \"Role\" # } # ], # \"resourceAppId\": \"00000003-0000-0000-c000-000000000000\" # } Reference:\nnielskok.tech how-to-create-service-principal-portal how-to-authenticate-service-principal-cli how to-add-app-roles-in-azure-ad-apps"},"title":"Getting Started with MSGraph API"},"/bensiegils/posts/2023-03-23-sgraph-securescore/":{"data":{"":"Get your Microsoft 365 Secure Score using the Microsoft Graph API to monitor your tenant’s security posture and track improvements.","secure-score-for-o365-tenant#Secure Score for O365 Tenant":"Getting the secure score for a tenant is a bit more complicated than getting the last logon time of a user. You only need to call the following endpoint: https://graph.microsoft.com/beta/security/secureScores and divide the result by 100 to get the percentage.\n# Needs permission SecurityEvents.Read.All $ClientID = '' $ClientSecret = '' $tenant_Id = '' # Connect to Graph # $Body = @{ Grant_Type = \"client_credentials\" resource = \"https://graph.microsoft.com\" client_id = $clientId client_secret = $clientSecret } $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body # Variable Collections # $path = \"C:\\temp\\\" $Headers = @{ 'Content-Type' = \"application/json\" 'Authorization' = \"Bearer $($ConnectGraph.access_token)\" } $token = $ConnectGraph.access_token # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 function Get-GraphData { param ( [parameter(Mandatory)] [string]$AccessToken, [parameter(Mandatory)] [string]$Uri ) $Headers = @{ 'Authorization' = \"Bearer $AccessToken\" } do { $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop $QueryResults += $Results.value $Uri = $Results.'@odata.nextLink' } while ($Uri) return $QueryResults } #This request get SecureScore $uri = \"https://graph.microsoft.com/beta/security/secureScores\" $Result = @() [array]$Response = Get-GraphData -AccessToken $Token -Uri $uri if ($Response) { ForEach ($Respons in $Response) { $SecureScore = $Respons.currentScore / $Respons.maxScore * 100 $Result += New-Object PSObject -property $([ordered]@{ CreatedDateTime = $Respons.createdDateTime CurrentScore = $Respons.currentScore MaxScore = $Respons.maxScore LicensedUserCount = $Respons.licensedUserCount ActiveUserCount = $Respons.activeUserCount SecureScore = [math]::Round($SecureScore, 2) }) } } else { Write-Host \"No SecureScore data found\" } # export to csv $Result | export-csv -path \"$path\\SecureScore.csv\" -NoTypeInformation"},"title":"MS Graph API - Get Secure Score for tenant"},"/bensiegils/posts/2023-03-23-sgraph-users/":{"data":{"":"Microsoft Graph API can be used to get comprehensive user information including the last logon time. This guide shows how to query user data including DisplayName, UserPrincipalName, UsageLocation, Country, LastSignInDateTime, IsLicensed, and IsGuestUser.","what-this-query-retrieves#What This Query Retrieves":"DisplayName, UserPrincipalName, UsageLocation, Country LastSignInDateTime, IsLicensed, IsGuestUser Complete user activity and licensing information #client_id and client_secret are generated in Azure AD $ClientID = '' $ClientSecret = '' $tenant_Id = '' # Create the body of the request. $Body = @{ Grant_Type = \"client_credentials\" resource = \"https://graph.microsoft.com\" client_id = $clientId client_secret = $clientSecret } # Get the access token. $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 # Get the access token. $token = $ConnectGraph.access_token # Variable Collections # $Result = @() #This request get users list with signInActivity. $Uri = \"https://graph.microsoft.com/beta/users?$select=displayName,userPrincipalName,contry,UsageLocation,userType,assignedLicenses,signInActivity,lastSignInDateTime\u0026$top=999\" #function to get graph data with pagination function Get-GraphData { param ( [parameter(Mandatory)] [string]$AccessToken, [parameter(Mandatory)] [string]$Uri ) $Headers = @{ 'Authorization' = \"Bearer $AccessToken\" } do { $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop $QueryResults += $Results.value $Uri = $Results.'@odata.nextLink' } while ($Uri) return $QueryResults } # Get the users. [array]$Users = Get-GraphData -AccessToken $Token -Uri $uri # Loop through the results and add them to the output array. ForEach ($User in $Users) { $Result += New-Object PSObject -property $([ordered]@{ DisplayName = $User.displayName UserPrincipalName = $User.userPrincipalName UsageLocation = $user.usageLocation Contry = $User.country LastSignInDateTime = if ($User.signInActivity.lastSignInDateTime) { [DateTime]$User.signInActivity.lastSignInDateTime } Else { $null } IsLicensed = if ($User.assignedLicenses.Count -ne 0) { $true } else { $false } IsGuestUser = if ($User.userType -eq 'Guest') { $true } else { $false } }) } # Write the results to a CSV file. $Logfile = \"lastlogon.csv\" $LogItem = New-Item -ItemType File -Name $Logfile $Result | ConvertTo-Csv | Out-File $LogItem -Append"},"title":"MS Graph API - Get User info"},"/bensiegils/posts/2023-04-04-hottub/":{"data":{"":"This is my hot tub controller with outdoor shower controller. It is based on an ESP32 and a 4-channel relay module with multiple DS18B20 temperature sensors for comprehensive monitoring.","features#Features":"ESP32 microcontroller with 4-channel relay module Multiple DS18B20 temperature sensors for hot tub and outdoor shower Water temperature monitoring ESPHome configuration for Home Assistant integration esphome: name: pottastyring platform: ESP32 board: nodemcu-32s wifi: ssid: \"\" password: \"\" domain: .lan manual_ip: static_ip: 192.168.x.x gateway: 192.168.x.x subnet: 255.255.255.0 dns1: 192.168.x.x # Enable fallback hotspot (captive portal) in case wifi connection fails ap: ssid: \"hottub\" password: \"\" captive_portal: web_server: port: 80 # Enable logging logger: # Enable Home Assistant API api: ota: time: - platform: sntp id: timer servers: - 0.pool.ntp.org - 1.pool.ntp.org - 2.pool.ntp.org dallas: - pin: GPIO13 sensor: - platform: dallas address: 0x67011464EA7EFF28 name: \"Pottur hiti\" id: pottur_hiti - platform: dallas address: 0x8B0314649975FF28 name: \"Vatn i pott\" id: vatn_i_hiti - platform: dallas address: 0x110000045976f328 name: \"Hiti Skapur\" id: Hiti_skapur - platform: dallas address: 0xe10314645814ff28 name: \"Hiti Uti\" id: hiti_uti binary_sensor: - platform: gpio filters: - delayed_on: 100ms id: fylla pin: number: GPIO17 mode: INPUT_PULLUP inverted: True name: \"Pottur fylla takki\" on_press: if: condition: lambda: 'return id(pottur_hiti).state \u003c 20;' then: - logger.log: \"The sensor value is below 20!\" - switch.turn_on: relay_1 - delay: 1min - switch.turn_on: relay_4 - delay: 30min - switch.turn_off: relay_1 - delay: 3min - climate.control: id: pottur_climate mode: \"HEAT\" else: - logger.log: \"The sensor value is above 20!\" - platform: gpio filters: - delayed_on: 500ms id: sturta pin: number: GPIO21 mode: INPUT_PULLUP inverted: True name: \"Sturta takki\" on_press: if: condition: lambda: 'return id(pottur_hiti).state \u003e 38;' then: - logger.log: \"The sensor value is above 38!\" - climate.control: id: pottur_climate mode: \"OFF\" - delay: 10sec - switch.turn_on: relay_3 - delay: 4min - switch.turn_off: relay_3 else: - logger.log: \"The sensor value is below 20!\" - switch.turn_on: relay_3 - delay: 4min - switch.turn_off: relay_3 - platform: gpio filters: - delayed_on: 500ms id: nidurfall pin: number: GPIO33 mode: INPUT_PULLUP inverted: True name: \"taema takki\" on_press: then: - switch.turn_off: relay_4 - climate.control: id: pottur_climate mode: \"off\" switch: - platform: gpio restore_mode: ALWAYS_OFF name: \"Pottur fylla relay\" pin: GPIO25 id: relay_1 - platform: gpio restore_mode: ALWAYS_OFF name: \"Pottur hita relay\" pin: GPIO26 id: relay_2 - platform: gpio restore_mode: ALWAYS_OFF name: \"Sturta relay\" pin: GPIO27 id: relay_3 - platform: gpio restore_mode: ALWAYS_ON name: \"Loka nidurfalli\" pin: GPIO18 id: relay_4 climate: - platform: bang_bang id: pottur_climate visual: min_temperature: 38 max_temperature: 42 temperature_step: 1.0 name: \"Pottur vatn\" sensor: pottur_hiti default_target_temperature_low: 38 °C default_target_temperature_high: 40 °C heat_action: if: condition: lambda: 'return id(pottur_hiti).state \u003e 32;' then: - logger.log: \"The sensor is above 32! then full\" - switch.turn_on: relay_1 - switch.turn_on: relay_2 else: - logger.log: \"The sensor value is below 32!\" - switch.turn_on: relay_1 - delay: 1min - switch.turn_on: relay_4 - delay: 30min - switch.turn_on: relay_2 idle_action: - switch.turn_off: relay_2 - switch.turn_off: relay_1 mqtt: broker: 192.168.x.x username: xxx password: xxx"},"title":"Esp32 Hot tub controller"},"/bensiegils/posts/2023-04-04-upgrade-hyper/":{"data":{"":"Use Azure Arc to automate updates on standalone Hyper-V hosts with intelligent VM management during maintenance windows.","azure-arc-hyper-v-host-management#Azure Arc Hyper-V Host Management":"Azure Arc is a powerful tool for managing and updating hybrid infrastructure, including standalone Hyper-V hosts. This demo shows how to use Azure Arc to update a standalone Hyper-V host, using a scheduled update task in Automation Account and pre and post scripts that shut down and start up VMs.\nPre-requisites\n# Stop all running VMs on the Hyper-V host and wait for them to shut down # save the names of the running VMs to a file $filePath = \"C:\\temp\\runningvm.txt\" (Get-vm | Where-Object { $_.State -eq \"Running\" }).name | Out-File $filePath $runningvm = Get-Content $filePath foreach ($Name in $runningvm) { Stop-VM $Name do { $VM1 = get-vm -Name $Name Write-Progress -Activity \"Waiting for the VM to shutdown\" } until ($Null -eq $VM1.Heartbeat) } # send a webhook to Teams to notify that the VMs have been shut down $webhookUri = \"\" $body = @{ \"@context\" = \"http://schema.org/extensions\" \"@type\" = \"MessageCard\" \"themeColor\" = \"d70000\" \"title\" = \"Send Webhook to Teams\" \"text\" = \"This is a message sent from Powershell\" } Invoke-RestMethod -Uri $webhookUri -Method Post -Body (ConvertTo-Json -InputObject $body) Post-requisites\n# Start up all VMs that were shut down during the update process $filePath = \"C:\\temp\\runningvm.txt\" $runningvm = Get-Content $filePath foreach ($Name in $runningvm) { Start-VM $Name do { $network = get-vm -name $name | get-VMNetworkAdapter Write-Progress -Activity \"Waiting for VM Network\" } until ($network.Status -eq \"ok\") # Wait for the VM and sleep for 60 seconds for next vm to start ( boot storm if all VMs are started at once) sleep -seconds 60 } # send a webhook to Teams to notify that the VMs have been started $webhookUri = \"\" $body = @{ \"@context\" = \"http://schema.org/extensions\" \"@type\" = \"MessageCard\" \"themeColor\" = \"d70000\" \"title\" = \"Send Webhook to Teams\" \"text\" = \"This is a message sent from Powershell\" } Invoke-RestMethod -Uri $webhookUri -Method Post -Body (ConvertTo-Json -InputObject $body) Updating a standalone Hyper-V host can be a complex and time-consuming process, but with Azure Arc and Automation Accounts, you can automate much of the work and ensure a smooth, reliable update process. Hyper-v cluster or HCI is a different story. {: .prompt-info }"},"title":"Upgrade Hyper-V Hosts with Azure Arc"},"/bensiegils/posts/2023-04-06-speedtest/":{"data":{"":"Monitor your internet connection performance with this PowerShell script that uses the Speedtest CLI and stores results in Azure Table Storage for historical analysis.\nInfo: The script uses the speedtest CLI from https://www.speedtest.net/apps/cli","problem-and-solution#Problem and Solution":"Was having problems with my internet connection and wanted to monitor it continuously. So I rewrote this script to use PowerShell and store the results in Azure Table Storage for tracking and analysis.\n#$StorageAccountName = \"StorageAcount\" #$Key = \"Storagekey\" #$StorageContext = New-AzStorageContext -StorageAccountName $StorageAccountName -StorageAccountKey $Key #$Table = (Get-AzStorageTable -Context $StorageContext | Where-Object {$_.name -eq \"Speedtest\"}).CloudTable $applocation = \"C:\\apps\\speedtest\" $path = \"C:\\temp\\\" $SpeedTestResults=@() $SpeedtestObj=@() $i = 0 while ($i -eq 0) { $PartitionKey = \"1\" $SpeedTestResults = \u0026 \"$($applocation)\\speedtest.exe\" --progress=no --format=json $SpeedtestResults = $SpeedTestResults | ConvertFrom-Json $SpeedtestObj += [PSCustomObject] @{ Time = Get-Date -Format \"dd/MM/yyyy HH:mm K\" downloadspeed = [math]::Round($SpeedtestResults.download.bandwidth / 1000000 * 8, 2) uploadspeed = [math]::Round($SpeedtestResults.upload.bandwidth / 1000000 * 8, 2) packetloss = ($($SpeedtestResults.packetLoss).ToString(\"P\")) isp = $SpeedtestResults.isp ExternalIP = $SpeedtestResults.interface.externalIp InternalIP = $SpeedtestResults.interface.internalIp UsedServer = $SpeedtestResults.server.host location = $SpeedTestResults.server.location Jitter = [math]::Round($SpeedtestResults.ping.jitter) Latency = [math]::Round($SpeedtestResults.ping.latency) } # ---- Move to table storage ---- # Add-AzTableRow -table $Table -PartitionKey $PartitionKey -RowKey (Get-Date).Ticks -property $SpeedtestObj Start-Sleep -Seconds 15 } #$SpeedtestObj | Format-Table | Out-String|ForEach-Object {Write-Host $_} $SpeedtestObj | Export-Csv -Path $path\\speedtest.csv -NoTypeInformation"},"title":"Powershell Speedtest"},"/bensiegils/posts/2023-04-07-apps-exp/":{"data":{"":"Monitor Azure AD application registrations for expiring certificates and secrets to prevent service disruptions. This script identifies expiring, expired, and apps with no expiration dates.","azure-ad-application-expiration-monitoring#Azure AD Application Expiration Monitoring":"This script will check all registered apps in Azure AD and will return the following information: expiring apps, expired apps, and apps with no expiration date.\n# needs permission Application.Read.All,Directory.Read.All $ClientID = '' $ClientSecret = '' $tenant_Id = '' $TenantName = $Body = @{ Grant_Type = \"client_credentials\" resource = \"https://graph.microsoft.com\" client_id = $clientId client_secret = $clientSecret } $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body # Variable Collections # $path = \"C:\\temp\\\" $today = Get-Date $Headers = @{ 'Content-Type' = \"application/json\" 'Authorization' = \"Bearer $($ConnectGraph.access_token)\" } $token = $ConnectGraph.access_token # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 function Get-GraphData { param ( [parameter(Mandatory)] [string]$AccessToken, [parameter(Mandatory)] [string]$Uri ) $Headers = @{ 'Authorization' = \"Bearer $AccessToken\" } do { $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop $QueryResults += $Results.value $Uri = $Results.'@odata.nextLink' } while ($Uri) return $QueryResults } #This request get application info $uri = \"https://graph.microsoft.com/beta/applications/\" [array]$apps = Get-GraphData -AccessToken $Token -Uri $uri $credentials = @() if ($apps) { foreach ($app in $apps) { $ApiUrl = \"https://graph.microsoft.com/beta/applications/\"+$app.id+\"/owners\" $owner = Invoke-WebRequest -Method GET -Uri $ApiUrl -ContentType \"application/json\" -Headers $headers | ConvertFrom-Json $app.KeyCredentials | foreach-object { #write-host $_.KeyId $_.DisplayName $credentials += [PSCustomObject] @{ CredentialType = \"KeyCredentials\"; DisplayName = $app.DisplayName; AppId = $app.AppId; ExpiryDate = $_.EndDateTime; StartDate = $_.StartDateTime; #KeyID = $_.KeyId; Type = $_.Type; Usage = $_.Usage; Owners = $owner.value.userPrincipalName; Expired = (([DateTime]$_.EndDateTime) -lt $today) ? \"Yes\" : \"No\"; } } $app.PasswordCredentials | foreach-object { #write-host $_.KeyId $_.DisplayName $credentials += [PSCustomObject] @{ CredentialType = \"PasswordCredentials\"; DisplayName = $app.DisplayName; AppId = $app.AppId; ExpiryDate = $_.EndDateTime; StartDate = $_.StartDateTime; #KeyID = $_.KeyId; Type = 'NA'; Usage = 'NA'; Owners = $owner.value.userPrincipalName; Expired = (([DateTime]$_.EndDateTime) -lt $today) ? \"Yes\" : \"No\"; } } } } $credentials | Export-Csv -Path $path\\credentials.csv -NoTypeInformation #$credentials | Format-Table | Out-String|ForEach-Object {Write-Host $_} Reference: https://pnp.github.io/script-samples/aad-apps-expired-keys/README.html?tabs=graphps"},"title":"Apps Expiration Azure AD"},"/bensiegils/posts/2023-04-22-aztfexport/":{"data":{"":"Get started with Terraform and Azure by exporting existing infrastructure using aztfexport. This Azure-specific tool makes it easy to convert your current Azure resources into Terraform templates.\nI like to watch videos on how to do things, but I don’t like to start from scratch. I prefer having a template to start and test things out. That’s why I looked into exporting Azure configurations to templates. While Terraformer can export existing cloud infrastructure to Terraform code, I prefer aztfexport because it’s more Azure-specific.","and-we-need-also-azure-cli#And we need also Azure Cli":"c:\\winget install azure-cli","export-to-terraform#Export to Terraform":"So I start with a simple resource group. And export it to Terraform’s current folder.\nc:\\dashboard\\aztfexport rg Dashboard There will be a menu list, and we will use w to import Terraform files.","install-aztfexport-is-easy-from-package-manager#Install aztfexport is easy from package manager":"c:\\winget install aztfexport","login-to-azure#Login to Azure":"This was the part I struggled with: where is the config file? It was too simple: login to Azure with Azure Cli and then select the subscription I wanted to export from. Terraform, Terraformer, and aztfexport will use the same subscription as Azure Cli.\nSo if you try to export and it fails to run, you need to login to Azure Cli. {: .prompt-tip }\nc:\\az login","result-is-a-terraform-files#Result is a Terraform files":"So we can start from there and try out things. The first is to test if the Terraform plan works.\nc:\\dashboard\\terraform plan {: .normal-image} Bingo, the plan works, so we can start to add more resources to the Terraform files.","select-subscription#Select subscription":"c:\\az account list -o table c:\\az account set --subscription \"MySubscription\""},"title":"Getting started with Terraform and Azure"},"/bensiegils/posts/2023-04-26-old-guest-accounts/":{"data":{"":"This is a rewrite from here office365itpros.com I have added some more properties to the report. And use msgraph instead of mggraph.\n# Needs permission User.Read.All $ClientID = '' $ClientSecret = '' $tenant_Id = '' # Connect to Graph # $Body = @{ Grant_Type = \"client_credentials\" resource = \"https://graph.microsoft.com\" client_id = $clientId client_secret = $clientSecret } $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body # Variable Collections # $Headers = @{ 'Content-Type' = \"application/json\" 'Authorization' = \"Bearer $($ConnectGraph.access_token)\" } $token = $ConnectGraph.access_token # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 function Get-GraphData { param ( [parameter(Mandatory)] [string]$AccessToken, [parameter(Mandatory)] [string]$Uri ) $Headers = @{ 'Authorization' = \"Bearer $AccessToken\" } do { $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop $QueryResults += $Results.value $Uri = $Results.'@odata.nextLink' } while ($Uri) return $QueryResults } #This request get users list with signInActivity. $uri = \"https://graph.microsoft.com/beta/users\" $Result = @() [array]$Response = Get-GraphData -AccessToken $Token -Uri $uri if ($Response) { ForEach ($Respons in $Response) { $Result += New-Object PSObject -property $([ordered]@{ DisplayName = $Respons.displayName UserPrincipalName = $Respons.userPrincipalName UsageLocation = $Respons.usageLocation Contry = $Respons.country LastSignInDateTime = if($Respons.signInActivity.lastSignInDateTime) { [DateTime]$Respons.signInActivity.lastSignInDateTime } Else {$null} IsLicensed = if ($Respons.assignedLicenses.Count -ne 0) { $true } else { $false } IsGuestUser = if ($Respons.userType -eq 'Guest') { $true } else { $false } RefreshTokensValidFromDateTime = $Respons.RefreshTokensValidFromDateTime onPremisesDistinguishedName = $Respons.onPremisesDistinguishedName }) } } else { Write-Host \"No User data found\" } $GuestUsers = $Result | Where-Object{$_.IsGuestUser -eq \"TRUE\"} $GuestAccountAge = 365 # Value used for guest age comparison. If you want this to be a different value (like 30 days), change this here. #$GuestUsers = $users.value -All $true -Filter \"UserType eq 'Guest'\" | Sort DisplayName $Today = (Get-Date); $StaleGuests = 0 $Report = [System.Collections.Generic.List[Object]]::new() # Check each account and find those over 365 days old ForEach ($Guest in $GuestUsers) { $AADAccountAge = ($Guest.RefreshTokensValidFromDateTime | New-TimeSpan).Days If ($AADAccountAge -gt $GuestAccountAge) { $StaleGuests++ #Write-Host \"Processing\" $Guest.DisplayName $i = 0; $GroupNames = $Null # Find what Microsoft 365 Groups the guest belongs to... if any $ReportLine = [PSCustomObject]@{ UPN = $Guest.UserPrincipalName Name = $Guest.DisplayName Age = $AADAccountAge Created = $Guest.RefreshTokensValidFromDateTime } $Report.Add($ReportLine) } } # Output the report $Report | Sort Age -Descending | Format-Table -AutoSize Write-Host \"Found\" $StaleGuests \"stale guest accounts.\" #reference: https://office365itpros.com/2019/10/15/report-old-guest-accounts/"},"title":"Getting old guest accounts in Azure AD"},"/bensiegils/posts/2023-05-03-azure-cost-cli/":{"data":{"":"Azure-Cost-CLI is a powerful tool to get cost information from Azure directly from the command line. GitHub Repository","azure-cost-overview#Azure Cost Overview":"","benefits-of-this-tool#Benefits of This Tool":"Get cost information without logging into the Azure portal Send Teams messages with cost information Send emails with cost reports Perfect for automation and scheduled reporting","by-location#By Location":"Location Amount EU West 8,23 EUR Unassigned 4,96 EUR US West 4,07 EUR EU North 1,88 EUR Unknown 0,26 EUR pie\rtitle Cost by location\r\"EU West\" : 8.23\r\"Unassigned\" : 4.96\r\"US West\" : 4.07\r\"EU North\" : 1.88\r\"Unknown\" : 0.26","by-resource-group#By Resource Group":"Resource Group Amount bensa 6,80 EUR microsoft.security 4,96 EUR backuptest 4,07 EUR alitis 2,22 EUR test2 1,35 EUR pie\rtitle Cost by resource group\r\"bensa\" : 6.80\r\"microsoft.security\" : 4.96\r\"backuptest\" : 4.07\r\"alitis\" : 2.22\r\"test2\" : 1.35 Generated at 2023-05-09 23:33:20","by-service-name#By Service Name":"Service Amount Backup 21,92 EUR Security Center 9,88 EUR Azure App Service 2,52 EUR Virtual Network 1,40 EUR Log Analytics 1,21 EUR Sentinel 1,00 EUR Azure DNS 0,52 EUR Storage 0,31 EUR Advanced Threat Protection 0,04 EUR Others 0,00 EUR pie\rtitle Cost by service\r\"Backup\" : 21.92\r\"Security Center\" : 9.88\r\"Azure App Service\" : 2.52\r\"Virtual Network\" : 1.40\r\"Log Analytics\" : 1.21\r\"Sentinel\" : 1.00\r\"Azure DNS\" : 0.52\r\"Storage\" : 0.31\r\"Advanced Threat Protection\" : 0.04\r\"Others\" : 0.00","totals#Totals":"Period Amount Today 0,90 EUR Yesterday 2,21 EUR Last 7 days 17,26 EUR Last 30 days 19,40 EUR gantt\rtitle Accumulated cost\rdateFormat X\raxisFormat %s\rsection 01 maí\rEUR 2,14 :0, 214\rsection 02 maí\rEUR 4,24 :0, 424\rsection 03 maí\rEUR 6,37 :0, 637\rsection 04 maí\rEUR 8,51 :0, 851\rsection 05 maí\rEUR 11,00 :0, 1100\rsection 06 maí\rEUR 13,61 :0, 1361\rsection 07 maí\rEUR 16,29 :0, 1629\rsection 08 maí\rEUR 18,50 :0, 1850\rsection 09 maí\rEUR 19,40 :0, 1940\rsection 10 maí\rEUR 21,36 : done, 0, 2136\rsection 11 maí\rEUR 23,33 : done, 0, 2333\rsection 12 maí\rEUR 25,52 : done, 0, 2552\rsection 13 maí\rEUR 27,71 : done, 0, 2771\rsection 14 maí\rEUR 30,04 : done, 0, 3004\rsection 15 maí\rEUR 32,19 : done, 0, 3219\rsection 16 maí\rEUR 34,08 : done, 0, 3408\rsection 17 maí\rEUR 35,99 : done, 0, 3599\rsection 18 maí\rEUR 37,91 : done, 0, 3791\rsection 19 maí\rEUR 40,04 : done, 0, 4004\rsection 20 maí\rEUR 42,18 : done, 0, 4218\rsection 21 maí\rEUR 44,46 : done, 0, 4446\rsection 22 maí\rEUR 46,54 : done, 0, 4654\rsection 23 maí\rEUR 48,39 : done, 0, 4839\rsection 24 maí\rEUR 50,24 : done, 0, 5024\rsection 25 maí\rEUR 52,10 : done, 0, 5210\rsection 26 maí\rEUR 54,18 : done, 0, 5418\rsection 27 maí\rEUR 56,26 : done, 0, 5626\rsection 28 maí\rEUR 58,48 : done, 0, 5848\rsection 29 maí\rEUR 60,51 : done, 0, 6051\rsection 30 maí\rEUR 62,30 : done, 0, 6230\rsection 31 maí\rEUR 64,10 : done, 0, 6410"},"title":"Azure Cost CLI"},"/bensiegils/posts/2023-05-10-three-tool/":{"data":{"":"Always in need of great tools to enhance Azure management and visualization. Here are three powerful tools that can help streamline your Azure operations.\nAzure Quick Review Azure Quick Review (azqr) goal is to produce a high level assessment of an Azure Subscription or Resource Group providing the following information for each Azure Service.\nAzure Visualizer PowerShell module to automatically generate Azure resource topology diagrams by just typing a PowerShell cmdlet and passing the name of one or more Azure Resource Group(s).\nAzure Cost CLI simple command line tool to get the cost of your Azure subscription."},"title":"Three great tools for Azure"},"/bensiegils/posts/2023-05-13-azureusage/":{"data":{"":"This will not work for Azure Plan subscriptions. ((400) Subscription scope usage is not supported for current api version. Please use api version after 2019-10-01) {: .prompt-info }","need-to-keep-track-of-your-azure-usage-here-is-a-way-to-use-github-actions-to-keep-track-of-your-usage-and-send-you-a-teams-message-if-you-are-over-a-certain-amount#Need to keep track of your Azure usage? here is a way to use github actions to keep track of your usage. And send you a Teams message if you are over a certain amount.":"We will need to enable webhook in Teams and add the webhook to the script, and create a Service Principal with access to the subscription you want to monitor. {: .prompt-tip }\nCreate Service Principal and give it access to the subscription you want to monitor. Copy the output from the command below and add it to the github repository as a secret, AZURE_CREDENTIALS.\naz ad sp create-for-rbac --name \"AzureUsage\" --role contributor --scopes /subscriptions/0692777c --sdk-auth {: .normal-image}\nWe will need to add secret to the repository, AZURE_CREDENTIALS, and add the output from the command above. {: .prompt-tip } {: .normal-image}\nGithub actions, it runs every day at midnight.\ncron: ‘0 0 * * *’ # every day at midnight This is the workflow file\n# File: .github/workflows/workflow.yml on: schedule: - cron: '0 0 * * *' # every day at midnight name: AzureUsage jobs: build-and-deploy: runs-on: ubuntu-latest steps: - uses: azure/login@v1 with: creds: ${{ secrets.AZURE_CREDENTIALS }} enable-AzPSSession: true - name: Run Azure PowerShell script uses: azure/powershell@v1 with: inlinescript: | $startDate = (Get-Date).AddDays(-2).ToString(\"yyyy-MM-dd\") $endDate = (Get-Date).AddDays(-1).ToString(\"yyyy-MM-dd\") $twodaysago = Get-AzConsumptionUsageDetail -StartDate $startDate -EndDate $startDate | Measure-Object -Property PretaxCost -Sum | Select-Object Sum $yesterday = Get-AzConsumptionUsageDetail -StartDate $enddate -EndDate $enddate | Measure-Object -Property PretaxCost -Sum | Select-Object Sum $twodaysago = [math]::Floor($twodaysago.sum) $yesterday = [math]::ceiling($yesterday.sum) $percentof = [math]::Floor($twodaysago * 1.4) if ($twodaysago -le $percentof -and $yesterday -lt 100) { Write-Host \"OK: Yesterday's Azure spending ($yesterday Euro) is not 40% more than 2 days ago ($twodaysago Euro) and not more than 100 Euro | yesterday=$yesterday, spending2daysago=$twodaysago\" } else { Write-Host \"Alarm!! Tom Much Azure Spending\" $webhookUri = \"webhook from teams\" $body = @{ \"@context\" = \"http://schema.org/extensions\" \"@typecod\" = \"MessageCard\" \"themeColor\" = \"d70000\" \"title\" = \"Alarm!! To Much Azure Spending\" \"text\" = \"Some thing is wrong in Azure. Yesterday's Azure spending ($yesterday Euro) is 40% more than 2 days ago ($twodaysago Euro) or more than 100 Euro\" } Invoke-RestMethod -Uri $webhookUri -Method Post -Body (ConvertTo-Json -InputObject $body) } azPSVersion: \"latest\""},"title":"Monitor Azure usage with github actions"},"/bensiegils/posts/2023-05-17-azureusageresource/":{"data":{"":"Why do we need to monitor Azure usage? Well, if you have a subscription with a spending limit, you need to keep track of your usage. If you go over the spending limit, your resources will be disabled. And you will need to pay for the overage.\nInfo: My concern is that some one gets a hold of my subscription, and start to use it. And I will get a big bill at the end of the month.\nUsing Get-AzConsumptionUsageDetail to get the usage for a subscription. Works not for Azure Plan subscriptions. Bcause of this error: ((400) Subscription scope usage is not supported for current api version. Please use api version after 2019-10-01)\nTip: But we can use the Microsoft.Consumption/usageDetails API to get the usage for a subscription.\nFirst we need to create a Service Principal, and we need to give service principal billing role on the subscription.\n#This script will get the usage for a subscription $startDate = (Get-Date).AddDays(-2).ToString(\"yyyy-MM-dd\") $endDate = (Get-Date).AddDays(-1).ToString(\"yyyy-MM-dd\") #set the variables $ClientID = '' $ClientSecret = '' $tenant_Id = '' $subscriptionId = '' # Set the URI for the request. $uri1 = \"https://management.azure.com/subscriptions/$subscriptionId/providers/Microsoft.Consumption/usageDetails?api-version=2023-03-01\u0026startDate=${startDate}\u0026endDate=${startDate}\" $uri2 = \"https://management.azure.com/subscriptions/$subscriptionId/providers/Microsoft.Consumption/usageDetails?api-version=2023-03-01\u0026startDate=${endDate}\u0026endDate=${endDate}\" # Create the body of the request. $Body = @{ Grant_Type = \"client_credentials\" Resource = \"https://management.azure.com/\" client_id = $clientId client_secret = $clientSecret } $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body $Headers = @{ 'Content-Type' = \"application/json\" 'Authorization' = \"Bearer $($ConnectGraph.access_token)\" } # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 #function to get graph data with pagination function Get-GraphData { param ( [parameter(Mandatory)] [string]$AccessToken, [parameter(Mandatory)] [string]$Uri ) $Headers = @{ 'Authorization' = \"Bearer $AccessToken\" } do { $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop $QueryResults += $Results.value $Uri = $Results.'@odata.nextLink' } while ($Uri) return $QueryResults } #$useage = Invoke-WebRequest -Method GET -Uri $Uri -ContentType \"application/json\" -Headers $headers | ConvertFrom-Json $uritwodaysago = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri1 $uriyesterday = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri2 $Resultstwodaysago = $uritwodaysago | Select-Object -ExpandProperty properties | Measure-Object -Property costInBillingCurrency -Sum | Select-Object Sum $Resultyesterday = $uriyesterday | Select-Object -ExpandProperty properties | Measure-Object -Property costInBillingCurrency -Sum | Select-Object Sum $Resultstwodaysago = [math]::Floor($Resultstwodaysago.sum) $Resultyesterday = [math]::ceiling($Resultyesterday.sum) $percentof = [math]::Floor($Resultstwodaysago * 1.4) if ($Resultstwodaysago -le $percentof -and $Resultyesterday -lt 100) { Write-Host \"OK: Yesterday's Azure spending ($Resultyesterday Euro) is not 40% more than 2 days ago ($Resultstwodaysago Euro) and not more than 100 Euro | yesterday=$Resultyesterday, spending2daysago=$Resultstwodaysago\" } else { Write-Host \"Alarm!! Tom Much Azure Spending\" $webhookUri = \"webhook from teams\" $body = @{ \"@context\" = \"http://schema.org/extensions\" \"@typecod\" = \"MessageCard\" \"themeColor\" = \"d70000\" \"title\" = \"Alarm!! To Much Azure Spending\" \"text\" = \"Some thing is wrong in Azure. Yesterday's Azure spending ($Resultyesterday Euro) is 40% more than 2 days ago ($Resultstwodaysago Euro) or more than 100 Euro\" } Invoke-RestMethod -Uri $webhookUri -Method Post -Body (ConvertTo-Json -InputObject $body) }"},"title":"Monitor Azure Usage for a subscription"},"/bensiegils/posts/2023-05-28-defendercloudesecurescore-/":{"data":{"":"Create detailed reports of Azure Defender for Cloud security scores using API calls and export them to CSV format for sharing and progress tracking.","azure-defender-security-score-reporting#Azure Defender Security Score Reporting":"How to build a report of Azure Defender for Cloud score via API, and export it to CSV. Why do we need this? Share it with your stakeholders and show them the progress of your security posture.\nInfo: Need to create service principal with the following permissions: Read RBAC on each subscription.\n#set the variables $ClientID = '' $ClientSecret = '' $tenant_Id = '' # your subscription Ids $subscription_Ids = '' # Create the body of the request. $Body = @{ Grant_Type = \"client_credentials\" Resource = \"https://management.azure.com/\" client_id = $clientId client_secret = $clientSecret } $ConnectGraph = Invoke-RestMethod -Uri \"https://login.microsoft.com/$tenant_Id/oauth2/token?api-version=1.0\" -Method POST -Body $Body $Headers = @{ 'Content-Type' = \"application/json\" 'Authorization' = \"Bearer $($ConnectGraph.access_token)\" } # Force TLS 1.2. [Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12 #function to get graph data with pagination function Get-GraphData { param ( [parameter(Mandatory)] [string]$AccessToken, [parameter(Mandatory)] [string]$Uri ) $Headers = @{ 'Authorization' = \"Bearer $AccessToken\" } do { $Results = Invoke-RestMethod -Uri $Uri -Headers $Headers -ErrorAction Stop $QueryResults += $Results.value $Uri = $Results.'@odata.nextLink' } while ($Uri) return $QueryResults } # Get the data foreach ($subscription_Id in $subscription_Ids) { $uri1 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/secureScores?api-version=2020-01-01\" [array]$secureScores = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri1 $uri2 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/secureScores/ascScore/securescorecontrols?api-version=2020-01-01\" [array]$ascScores = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri2 $uri3 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/secureScoreControlDefinitions?api-version=2020-01-01\" [array]$secureScoreControlDefinitions = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri3 $uri4 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/assessments?api-version=2020-01-01\" [array]$assessments = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri4 $uri5 = \"https://management.azure.com/subscriptions/$subscription_Id/providers/Microsoft.Security/secureScores/ascScore/securescorecontrols?api-version=2020-01-01\u0026expand=definition\" [array]$securescorecontrols = Get-GraphData -AccessToken $ConnectGraph.access_token -Uri $uri5 } # Create the report $ReportLineScore = [PSCustomObject][Ordered]@{ MaxScore = $secureScores.Properties.score.max Current = $secureScores.Properties.score.current percentage = $secureScores.Properties.score.percentage * 100 } $SPData = [System.Collections.Generic.List[Object]]::new() ForEach ($ascScore in $ascScores) { $SPLine = [PSCustomObject][Ordered]@{ Name = $ascScore.properties.displayName Healthy = $ascScore.properties.healthyResourceCount UnHealthy = $ascScore.properties.unhealthyResourceCount NotApplicable = $ascScore.properties.notApplicableResourceCount weight = $ascScore.properties.weight maxScore = $ascScore.properties.score.max currentScore = $ascScore.properties.score.current percentage = $ascScore.properties.score.percentage * 100 } $SPData.Add($SPLine) } $SPData1 = [System.Collections.Generic.List[Object]]::new() foreach ($secureScoreControlDefinition in $secureScoreControlDefinitions) { $SPLine1 = [PSCustomObject][Ordered]@{ Name = $secureScoreControlDefinition.properties.displayName MaxScore = $secureScoreControlDefinition.properties.maxScore } $SPData1.Add($SPLine1) } $SPData2 = [System.Collections.Generic.List[Object]]::new() foreach ($assessment in $assessments) { $SPLine2 = [PSCustomObject][Ordered]@{ Name = $assessment.properties.displayName Status = $assessment.properties.status.description Code = $assessment.properties.status.code Cause = $assessment.properties.status.cause Details = $assessment.properties.resourceDetails.Id } $SPData2.Add($SPLine2) } $SPData3 = [System.Collections.Generic.List[Object]]::new() foreach ($securescorecontrol in $securescorecontrols) { $SPLine3 = [PSCustomObject][Ordered]@{ Name = $securescorecontrol.properties.displayName HealthyCount = $securescorecontrol.properties.healthyResourceCount UnHealthyCount = $securescorecontrol.properties.unhealthyResourceCount NotApplicableCount = $securescorecontrol.properties.notApplicableResourceCount } $SPData3.Add($SPLine3) } $ReportLineScore | Export-Csv -Path \"c:\\temp\\ReportLineScore.csv\" -NoTypeInformation -Encoding UTF8 $SPData | Export-Csv -Path \"c:\\temp\\SPData.csv\" -NoTypeInformation -Encoding UTF8 $SPData1 | Export-Csv -Path \"c:\\temp\\SPData1.csv\" -NoTypeInformation -Encoding UTF8 $SPData2 | Export-Csv -Path \"c:\\temp\\SPData2.csv\" -NoTypeInformation -Encoding UTF8 $SPData3 | Export-Csv -Path \"c:\\temp\\SPData3.csv\" -NoTypeInformation -Encoding UTF8 MaxScore Current percentage 31 24 77,42 Name MaxScore Protect applications against DDoS attacks 2 Enable MFA 10 Encrypt data in transit 4 Restrict unauthorized network access 4 Implement security best practices 0 Apply adaptive application control 3 Enable auditing and logging 1 Enable encryption at rest 4 Enable endpoint protection 2 Apply system updates 6 Manage access and permissions 4 Remediate security configurations 4 Secure management ports 8 Remediate vulnerabilities 6 Enable enhanced security features 0"},"title":"Get Azure Defender for Cloud score Via API"},"/bensiegils/posts/2023-09-30-hyper-v-tool/":{"data":{"":"My tool to create VMs in my lab environment with streamlined automation.\nGitHub Repository: https://github.com/Lubenz007/hyper-v-tool\nUtilizing a standalone Hyper-V server and generating VMs from a golden image might be considered an older approach, but it’s one I personally prefer. Over the years, I’ve diligently maintained a tool for crafting VMs on my Hyper-V host within the lab environment. I employ SSH to connect to the Hyper-V host and initiate the VM creation process. This tool provides a streamlined menu system that automatically configures the VM, allowing me to promptly begin using it.\nAll config is done in the vm_menu.ps1 You can find the oscdimg.exe in the Windows 11 22h2 ADK:\nhttps://learn.microsoft.com/en-us/windows-hardware/get-started/adk-install\nKit “C:\\Program Files (x86)\\Windows Kits\\10\\Assessment and Deployment Kit\\Deployment Tools\\arm64\\Oscdimg”\n$global:oscdimgPath = “$global:StartupFolder\\tools\\oscdimg.exe”\n#Template location\n$global:template = “$global:StartupFolder\\template”\n#template vhd name / windows is sysprep / Ubuntu cloud-init / modify for your template.\n$global:2022core = “W2022C.vhdx”\n$global:2022stand = “W2022S_OS.vhdx”\n$global:2022data = “W2022D_OS.vhdx”\n$global:Ubuntu = “Ubuntu_OS.vhd”"},"title":"hyper-v-tool"},"/bensiegils/posts/2023-10-08-azurearc-ssh/":{"data":{"":"If you have deployed Azure Arc, you have the option to utilize Windows Admin Center for Windows Machines. Additionally, you can enable the OpenSSH Extension on Windows Server, granting the capability to establish SSH tunnels to the localhost or other machines that support RDP/SSH connections.\nTo begin the process, please follow these steps:\nEnsure that you have the Azure CLI installed on your local computer. If it is not already installed, open PowerShell and execute the command: winget install -e –id Microsoft.AzureCLI.\nIf you are using a different operating system, refer to the official guide on how to install the Azure CLI provided by Microsoft Learn: How to install the Azure CLI | Microsoft Learn.\nNext, enable the OpenSSH extension on the VM where Azure Arc is deployed.\nLogon to Azure With Azure CLi PS C:\\\u003e az login Tip: Please use Multi-Factor Authentication for added security.\nThe we go to the Connect settings and select password authentication on the VM Copy the connect string and paste to Powershell and add “-L 3333:192.168.x.x:3389” the ip of the host you want to connect to.\naz ssh arc --subscription \"asdfasdfadf-adfadsfadsf-sdfc\" --resource-group \"Arc-Servers\" --name \"HYPER-01\" --local-user \"administrator\" \"-L 3333:192.168.81.25:3389\" And you are connect over SSH tunnel with RDP."},"title":"Azure Arc - (Azure Cli - ssh - rdp)"},"/bensiegils/posts/2023-10-15-outofdiskspace-teams/":{"data":{"":"Monitor disk space usage on Azure Arc-enabled servers and receive instant Microsoft Teams notifications when space is running low.","azure-arc-disk-space-monitoring#Azure Arc Disk Space Monitoring":"Upon successfully installing Azure Arc on your Server and activating Insights, you open the door to a powerful monitoring capability. One essential aspect is overseeing disk space usage on your server, ensuring optimal performance and preventing potential issues. This example provides a step-by-step guide on how to set up disk space monitoring and receive instant notifications via Microsoft Teams when space is running low.\nFurthermore, this versatile approach can be extended to send email alerts, providing an additional layer of flexibility in how you manage critical resource thresholds. This comprehensive monitoring strategy empowers you with the tools to proactively maintain your server’s health and responsiveness, bolstering the reliability of your operations.\nThe query below is a simple example of how to monitor disk space usage on your server. It returns the percentage of free space on the C: drive, which is then used to trigger an alert when the threshold is exceeded. The query can be customized to monitor other drives on your server, and the threshold can be adjusted to suit your needs.\nInsightsMetrics | where Name == \"FreeSpaceMB\" | summarize arg_max(TimeGenerated, *) by Tags, Computer | extend Drive = tostring(parse_json(Tags)[\"vm.azm.ms/mountId\"]) | extend Size = toreal(parse_json(Tags)[\"vm.azm.ms/diskSizeMB\"]) | project TimeGenerated, Computer, Drive, bin(SizeGB = Size / 1024, 0.1), bin(FreeGB = Val / 1024, 1) | join kind=inner (InsightsMetrics | where Name == \"FreeSpacePercentage\" | summarize arg_max(TimeGenerated, *) by Tags, Computer | extend Drive = tostring(parse_json(Tags)[\"vm.azm.ms/mountId\"]) | project TimeGenerated, Computer, Drive, bin(FreePercent = Val, 1.1))on Computer, Drive | project TimeGenerated, Computer, Drive, SizeGB, FreeGB, FreePercent | where FreePercent \u003c= 90.0 // //| where FreeGB \u003c= 10.0 | order by Computer asc We need to enable webhooks in Microsoft Teams and copy the webhook URL. Finally, we need to create Azure automation runbook and configure it to send notifications to the channel. We also need to enable the Azure Automation account to access the Log Analytics workspace. To do this, we need to give automation account read access to the Log Analytics workspace and resource group where the arc servers are located.\nthe runbook code is the following:\n# So we are going to use the same query as in Azure Monitor to get the results and send it to Teams # Connect to Azure for Log Analytics Connect-AzAccount -Identity $context = Set-AzContext -Subscription \"Your Subscription Name\" $workspaceName = \"arc-servers\" $workspaceRG = \"arc-servers\" $WorkspaceID = (Get-AzOperationalInsightsWorkspace -Name $workspaceName -ResourceGroupName $workspaceRG).CustomerID $query = \"InsightsMetrics | where Name == `\"FreeSpaceMB`\" | summarize arg_max(TimeGenerated, *) by Tags, Computer | extend Drive = tostring(parse_json(Tags)[`\"vm.azm.ms/mountId`\"]) | extend Size = toreal(parse_json(Tags)[`\"vm.azm.ms/diskSizeMB`\"]) | project TimeGenerated, Computer, Drive, bin(SizeGB = Size / 1024, 0.1), bin(FreeGB = Val / 1024, 1) | join kind=inner (InsightsMetrics | where Name == `\"FreeSpacePercentage`\" | summarize arg_max(TimeGenerated, *) by Tags, Computer | extend Drive = tostring(parse_json(Tags)[`\"vm.azm.ms/mountId`\"]) | project TimeGenerated, Computer, Drive, bin(FreePercent = Val, 1.1))on Computer, Drive | project TimeGenerated, Computer, Drive, SizeGB, FreeGB, FreePercent | where FreePercent \u003c= 90.0 // //| where FreeGB \u003c= 10.0 | order by Computer asc\" $kqlQuery = Invoke-AzOperationalInsightsQuery -WorkspaceId $WorkspaceID -Query $query $webhookUri = \"your webhook url\" # Define the message as a PowerShell object $message = @{ context = \"http://schema.org/extensions\" type = \"MessageCard\" themeColor = \"d70000\" title = \"Machine with low disk space\" text = \"$($kqlQuery.results | Format-List | Out-String)\" } # Convert the message to JSON $jsonMessage = $message | ConvertTo-Json # Send the message using Invoke-RestMethod Invoke-RestMethod -Method Post -ContentType 'application/json' -Body $jsonMessage -Uri $webhookUri Select create alert rule Create a new alert rule Create action group Select the runbook with teams notification that we create before\nthe result in teams"},"title":"Arc - Diskspace Monitoring - Teams)"},"/bensiegils/posts/2024-06-23-gspro-controlbox/":{"data":{"":"ESP32 code to create a GSPRO Control box with Bluetooth connectivity and 12 programmable keys for enhanced golf simulator control.","features#Features":"12 programmable keys with custom functions Bluetooth Low Energy connectivity Camera controls, scorecard display, pin viewing Arrow key navigation and visual settings // Benedikt Gabriel Egilsson - bensiegils.com // 1= 5 - Camera to ball // 2= KEY_M_CTRL - Muligan // 3= T - Scorecard display // 4= P - See the pin // 5= O - Flyover of the hole // 6= . - shadow quality // 7= B - Hide - Make objects in your line of sight invisible // 8= Z - Hide or show the 3D gras // 9= KEY_UP_ARROW // 10= KEY_DOWN_ARROW // 11= KEY_LEFT_ARROW // 12= KEY_RIGHT_ARROW #define USE_NIMBLE #include BleKeyboard bleKeyboard(\"GSPRO BOX\"); #define NUM_KEYS 12 struct Key { int pin; uint8_t code; bool state; bool isCtrl; // New field to indicate if Ctrl needs to be held }; Key keys[NUM_KEYS] = { {16, '5', false, false}, {17, 'm', false, true}, // 'm' with Ctrl modifier {18, 't', false, false}, {19, 'p', false, false}, {21, 'o', false, false}, {22, '.', false, false}, {32, 'b', false, false}, {33, 'z', false, false}, {27, KEY_UP_ARROW, false, false}, {14, KEY_DOWN_ARROW, false, false}, {12, KEY_LEFT_ARROW, false, false}, {13, KEY_RIGHT_ARROW, false, false} }; bool connectNotificationSent = false; void setup() { Serial.begin(115200); Serial.println(\"Code running...\"); // Set pin modes for (int i = 0; i \u003c NUM_KEYS; i++) { pinMode(keys[i].pin, INPUT_PULLUP); } // Initialize BLE keyboard bleKeyboard.begin(); } void loop() { if (bleKeyboard.isConnected()) { if (!connectNotificationSent) { Serial.println(\"BLE connected...\"); connectNotificationSent = true; } for (int i = 0; i \u003c NUM_KEYS; i++) { handleButton(i); } } else { if (connectNotificationSent) { Serial.println(\"BLE disconnected...\"); connectNotificationSent = false; } } delay(10); // Small delay to stabilize readings } void handleButton(int keyIndex) { bool currentState = !digitalRead(keys[keyIndex].pin); // Read the button state (active low) if (currentState != keys[keyIndex].state) { keys[keyIndex].state = currentState; if (currentState) { if (keys[keyIndex].isCtrl) { // Check if Ctrl modifier is needed bleKeyboard.press(KEY_LEFT_CTRL); } bleKeyboard.press(keys[keyIndex].code); Serial.print(\"Key pressed: \"); } else { bleKeyboard.release(keys[keyIndex].code); if (keys[keyIndex].isCtrl) { // Check if Ctrl modifier is needed bleKeyboard.release(KEY_LEFT_CTRL); } Serial.print(\"Key released: \"); } Serial.println(keys[keyIndex].code); } }"},"title":"GSPRO Control box"},"/bensiegils/posts/2025-08-19-move-vmware-azure/":{"data":{"":"When using a tool such as Disk2VHD, you need a storage location—and sometimes plenty of it—to export the virtual machine (VM). But what if no local storage is available, and no USB can be connected, such as with a VMware hosting provider?\nIn that case, you can export the VHD directly to an Azure File Share and then copy it to Azure Blob Storage. Note: Dynamically expanding disks are not supported in this process—you must use a fixed-size disk.\nThe next step is to provision a Windows Server in Azure, install Hyper-V, and use Hyper-V Manager to convert the disk to a fixed-size VHD.\nAfter conversion, you can upload the VHD to Azure, create an image from it, and then deploy a VM. In many cases, Azure will display an error during deployment stating that the VM cannot be customized. You can safely ignore this error.\nTools You Will Need\nDisk2VHD – for exporting the VMware VM to a VHD file. 🔗 Download Disk2VHD Azure Storage Explorer – for managing Azure File Shares and Blob Storage. 🔗 Download Azure Storage Explorer Hyper-V Manager – for converting VHDs from dynamic to fixed-size. Installed on VM in Azure Step 1: Mount Azure File Share\nOn the source VMware server and later on the Hyper-V server in Azure, mount the Azure File Share: Mount as Administrator because disk2vhd runs as Administrator.\nStep 2: Export VMware VM with Disk2VHD\nRun Disk2VHD on the source server.\nSelect the volumes you want to export.\nChoose the Azure File Share as the destination path (after mounting it as a network drive).\nStep 3: Convert VHD from Dynamic to Fixed\nOpen Hyper-V Manager on the Azure VM.\nGo to Edit Disk…\nBrowse to the VHD file from the Azure File Share.\nSelect Convert → Fixed size.\nStep 4: Copy VHD to Azure Blob Storage\nUse Azure Storage Explorer ( Use copy and paste in the menu :) )\nStep 5: Create Azure Managed Image \u0026 VM\nIn the Azure Portal, go to Images → + Create.\nSelect your uploaded VHD as the source.\nCreate an image.\nDeploy a VM from that image.\nNow you can create vm from the image."},"title":"Migrating from VMware to Azure using Azure Files"}}